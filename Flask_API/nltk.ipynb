{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/ericbertrand8686/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from newspaper import Article\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# telecharger l'article\n",
    "url = \"https://www.monde-diplomatique.fr/2022/02/TEURTRIE/64373\"\n",
    "article = Article(url)\n",
    "article.download()\n",
    "article.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukraine, pourquoi la crise\n"
     ]
    }
   ],
   "source": [
    "#afficher le titre\n",
    "print(article.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realiser du traitement de text nlp\n",
    "article.nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pourquoi', 'la', 'en', 'se', 'les', 'crise', 'le', 'du', 'pour', 'des', 'ukraine', 'et', 'à']\n"
     ]
    }
   ],
   "source": [
    "# afficher le mot clef\n",
    "print(article.keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('’', 22), ('de', 20), (',', 17), ('.', 14), ('l', 11), ('la', 11), ('en', 9), ('les', 8), ('des', 8), ('à', 8)]\n"
     ]
    }
   ],
   "source": [
    "# wrod count \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "wrd = word_tokenize(article.text)\n",
    "\n",
    "wrd_count = nltk.FreqDist(wrd)\n",
    "\n",
    "print(wrd_count.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pourquoi', 'la', 'en', 'se', 'les', 'crise', 'le', 'du', 'pour', 'des', 'ukraine', 'et', 'à']\n"
     ]
    }
   ],
   "source": [
    "# creer un tuple de mot clef\n",
    "keywords = article.keywords\n",
    "print (keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pourquoi': 0, 'la': 0, 'en': 0, 'se': 0, 'les': 0, 'crise': 0, 'le': 0, 'du': 0, 'pour': 0, 'des': 0, 'ukraine': 0, 'et': 0, 'à': 0}\n"
     ]
    }
   ],
   "source": [
    "# mettre les mots clef dans un dictionnaire\n",
    "keywords_dict = {}\n",
    "for i in range(len(keywords)):\n",
    "    keywords_dict[keywords[i]] = 0\n",
    "\n",
    "print (keywords_dict)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pourquoi': 1, 'la': 11, 'en': 9, 'se': 3, 'les': 8, 'crise': 0, 'le': 5, 'du': 4, 'pour': 5, 'des': 8, 'ukraine': 0, 'et': 6, 'à': 8}\n"
     ]
    }
   ],
   "source": [
    "# mettre les mots clef dans un dictionnaire avec le nombre d'occurence\n",
    "\n",
    "for i in range(len(wrd)):\n",
    "    if wrd[i] in keywords_dict:\n",
    "        keywords_dict[wrd[i]] += 1\n",
    "print(keywords_dict)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pourquoi 1\n",
      "la 11\n",
      "en 9\n",
      "se 3\n",
      "les 8\n",
      "crise 0\n",
      "le 5\n",
      "du 4\n",
      "pour 5\n",
      "des 8\n",
      "ukraine 0\n",
      "et 6\n",
      "à 8\n"
     ]
    }
   ],
   "source": [
    "# afficher le nombre d'occurence\n",
    "for i in keywords_dict:\n",
    "    print(i, keywords_dict[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(vocabulary={'crise': 0, 'des': 8, 'du': 4, 'en': 9, 'et': 6,\n",
      "                            'la': 11, 'le': 5, 'les': 8, 'pour': 5,\n",
      "                            'pourquoi': 1, 'se': 3, 'ukraine': 0, 'à': 8})\n"
     ]
    }
   ],
   "source": [
    "# creer un arbre binaire de recherche avec le dictionnaire\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "abr = CountVectorizer(vocabulary=keywords_dict)\n",
    "\n",
    "print (abr)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "655f344d7c6f243fd2a4e6bd2e7de9c8db0b4f5f417cf73f9f9b358b58ed0107"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
